# Web Scrapers

This repository contains a collection of Node.js-based web scrapers I built to explore and demonstrate different approaches to data extraction and automation.

Each script focuses on a specific task, such as:

- Sending HTTP requests and handling responses
- Parsing and traversing HTML with **Cheerio**
- Working with JSON and REST APIs
- Saving scraped data into CSV, JSON, or databases
- Handling pagination, rate limits, and basic error cases

---

## Purpose

The project serves as a showcase of practical scripting skills in **Node.js**, with an emphasis on automation, backend scripting, and systems integration. These scrapers are functional examples â€” designed more for learning and demonstration than production use.

---

## Usage

1. Clone the repository:
   ```bash
   git clone https://github.com/evokenull/web-scrapers.git
   cd web-scrapers
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Run a scraper:
   ```bash
   node scrapers/<script-name>.js
   ```
